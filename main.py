import os
import requests
import io
import sys
from datetime import datetime, timedelta
import pytz
from bs4 import BeautifulSoup
import yaml
import glob
import json
import hashlib
import subprocess
import smtplib
from email.mime.text import MIMEText
from email.header import Header

# å¼ºåˆ¶è®¾ç½®ç»ˆç«¯è¾“å‡ºä¸º UTF-8 ç¼–ç ï¼Œé˜²æ­¢ Windows ä¹±ç 
if sys.stdout.encoding != 'utf-8':
    try:
        import io
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    except Exception:
        pass

# é»˜è®¤è®¾ç½®
CONFIG_DIR = "COMM-CFG"
DATA_DIR = "data"
RECORD_FILE = os.path.join(DATA_DIR, "processed_records.json")
SINOPEC_HISTORY_FILE = os.path.join(DATA_DIR, "sinopec_butadiene_history.json")
NR_HISTORY_FILE = os.path.join(DATA_DIR, "natural_rubber_history.json")
PUSHPLUS_TOKEN = os.environ.get("PUSHPLUS_TOKEN")

# é‚®ä»¶é…ç½® (ä»ç¯å¢ƒå˜é‡è¯»å–)
EMAIL_SENDER = os.environ.get("EMAIL_SENDER")
EMAIL_AUTH_CODE = os.environ.get("EMAIL_AUTH_CODE")
EMAIL_RECEIVER = os.environ.get("EMAIL_RECEIVER")

def get_sinopec_factory_price():
    """è·å–ä¸­çŸ³åŒ–ä¸äºŒçƒ¯å½“æ—¥å‡ºå‚ä»· (ä»èµ„è®¯åˆ—è¡¨é¡µæŠ“å–)"""
    list_url = "https://www.100ppi.com/news/list-14--369-1.html"
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
    
    tz = pytz.timezone('Asia/Shanghai')
    today = datetime.now(tz)
    # æ ¼å¼åŒ–ä¸º "1æœˆ9æ—¥" è€Œä¸æ˜¯ "01æœˆ09æ—¥"ï¼Œä»¥åŒ¹é…ç½‘é¡µæ ‡é¢˜
    today_md = f"{today.month}æœˆ{today.day}æ—¥"
    
    try:
        resp = requests.get(list_url, headers=headers, timeout=15)
        resp.encoding = 'utf-8'
        soup = BeautifulSoup(resp.text, 'html.parser')
        
        # å¯»æ‰¾åŒ…å« "ä¸­çŸ³åŒ–ä¸äºŒçƒ¯å‡ºå‚ä»·æ ¼" çš„æ ‡é¢˜
        news_items = soup.find_all('div', class_='list-item') or soup.find_all('li')
        target_url = None
        for item in news_items:
            text = item.get_text()
            if today_md in text and "ä¸­çŸ³åŒ–ä¸2çƒ¯å‡ºå‚ä»·" in text.replace("äºŒ", "2") or \
               (today_md in text and "ä¸­çŸ³åŒ–" in text and "ä¸äºŒçƒ¯" in text and "ä»·æ ¼" in text):
                link = item.find('a')
                if link and link.get('href'):
                    target_url = link.get('href')
                    if not target_url.startswith('http'):
                        if target_url.startswith('/'):
                            target_url = "https://www.100ppi.com" + target_url
                        else:
                            target_url = "https://www.100ppi.com/" + target_url
                    break
        
        if not target_url:
            print(f"ä»Šæ—¥ ({today_md}) å°šæœªå‘å¸ƒä¸­çŸ³åŒ–ä¸äºŒçƒ¯å‡ºå‚ä»·èµ„è®¯ã€‚")
            return None

        # è¿›å…¥è¯¦æƒ…é¡µæŠ“å–å…·ä½“å‚å®¶ä»·æ ¼
        print(f"å‘ç°ä»Šæ—¥ä¸­çŸ³åŒ–èµ„è®¯: {target_url}ï¼Œæ­£åœ¨è§£æè¯¦æƒ…...")
        detail_resp = requests.get(target_url, headers=headers, timeout=15)
        detail_resp.encoding = 'utf-8'
        detail_soup = BeautifulSoup(detail_resp.text, 'html.parser')
        content = detail_soup.get_text()
        
        # ç®€å•è§£æé€»è¾‘ï¼šå¯»æ‰¾æ•°å­—
        # é€šå¸¸æ ¼å¼: "ä¸Šæµ·çŸ³åŒ–æ‰§è¡Œ9100å…ƒ/å¨", "æ‰¬å­çŸ³åŒ–æ‰§è¡Œ9100å…ƒ/å¨"
        # é¢„å®šä¹‰ä¸€äº›å¸¸è§å‚å®¶
        plants = ["ä¸Šæµ·çŸ³åŒ–", "æ‰¬å­çŸ³åŒ–", "é•‡æµ·ç‚¼åŒ–", "å¹¿å·çŸ³åŒ–", "èŒ‚åçŸ³åŒ–", "ä¸­éŸ©çŸ³åŒ–", "ä¸­ç§‘ç‚¼åŒ–"]
        prices = {}
        for p in plants:
            if p in content:
                # å¯»æ‰¾å‚å®¶åé¢çš„ 4 ä½æ•°å­—
                idx = content.find(p)
                import re
                match = re.search(r'(\d{4})', content[idx:idx+50])
                if match:
                    prices[p] = int(match.group(1))
        
        if not prices:
            # å¦‚æœæ²¡æŠ“åˆ°å…·ä½“çš„ï¼Œå°è¯•æŠ“é€šç¨¿ä¸­çš„ç»Ÿä¸€ä»·æ ¼
            match = re.search(r'æ‰§è¡Œ(\d{4})å…ƒ', content)
            if match:
                prices["ä¸­çŸ³åŒ–(ç»Ÿä¸€)"] = int(match.group(1))
        
        if prices:
            return {
                "date": today.strftime('%Y-%m-%d'),
                "prices": prices,
                "url": target_url
            }
    except Exception as e:
        print(f"æŠ“å–ä¸­çŸ³åŒ–å‡ºå‚ä»·å¤±è´¥: {e}")
    return None

def generate_sinopec_html(today_sinopec, history):
    """ä¸ºä¸­çŸ³åŒ–ä»·æ ¼ç”Ÿæˆä¸“é—¨çš„ HTML æŠ¥å‘Š"""
    tz = pytz.timezone('Asia/Shanghai')
    now_str = datetime.now(tz).strftime('%Y-%m-%d %H:%M')
    
    html = f"<h2>ğŸš€ ä¸­çŸ³åŒ–ä¸äºŒçƒ¯å‡ºå‚ä»·æ›´æ–°æŠ¥å‘Š</h2>"
    html += f"<p><b>æ›´æ–°æ—¶é—´:</b> {now_str}</p>"
    
    # 1. å½“æ—¥è¯¦æƒ…ä¸å¯¹æ¯”
    prices = today_sinopec['prices']
    avg_price = sum(prices.values()) / len(prices)
    
    html += "<h3>ğŸ“ ä»Šæ—¥å‚å®¶æŠ¥ä»·</h3>"
    html += '<table border="1" style="border-collapse: collapse; width: 100%; text-align: center;">'
    html += '<tr style="background:#eee;"><th>å‚å®¶</th><th>ä»·æ ¼ (å…ƒ/å¨)</th><th>çŠ¶æ€</th></tr>'
    
    for plant, price in prices.items():
        style = ""
        status = "æ­£å¸¸"
        if price != avg_price:
            style = 'style="background-color: #ffcdd2; color: red; font-weight: bold;"'
            status = "âš ï¸ ä»·æ ¼å¼‚å¸¸"
        
        html += f'<tr {style}><td>{plant}</td><td>{price}</td><td>{status}</td></tr>'
    html += "</table>"
    
    # 2. æœ€è¿‘7å¤©è¶‹åŠ¿
    html += "<h3>ğŸ“ˆ æœ€è¿‘ 7 å¤©ä»·æ ¼è¶‹åŠ¿</h3>"
    html += '<table border="1" style="border-collapse: collapse; width: 100%; text-align: center;">'
    html += '<tr style="background:#333; color:white;"><th>æ—¥æœŸ</th><th>æŠ¥ä»·</th><th>å˜åŠ¨</th></tr>'
    
    # åŒ…å«ä»Šå¤©åŠå†å²å‰6å¤©
    all_dates = history + [{"date": today_sinopec['date'], "price": int(avg_price)}]
    recent_7 = all_dates[-7:]
    recent_7.reverse() # æœ€æ–°çš„åœ¨å‰
    
    for i, entry in enumerate(recent_7):
        price = entry['price']
        change = "æŒå¹³"
        if i < len(recent_7) - 1:
            prev_price = recent_7[i+1]['price']
            diff = price - prev_price
            if diff > 0: change = f'<span style="color:red;">+{diff}</span>'
            elif diff < 0: change = f'<span style="color:green;">{diff}</span>'
            
        html += f"<tr><td>{entry['date']}</td><td>{price}</td><td>{change}</td></tr>"
    html += "</table>"
    html += f'<p style="font-size:12px;"><a href="{today_sinopec["url"]}">æŸ¥çœ‹åŸèµ„è®¯é¡µé¢</a></p>'
    
    return html

def get_natural_rubber_price():
    """è·å–å¤©ç„¶æ©¡èƒ¶å½“æ—¥æŠ¥ä»·åŠ¨æ€ (ä»èµ„è®¯åˆ—è¡¨é¡µæŠ“å–)"""
    list_url = "https://www.100ppi.com/news/list-15--56-1.html"
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
    
    tz = pytz.timezone('Asia/Shanghai')
    today = datetime.now(tz)
    date_pattern = f"{today.year}-{today.month:02d}-{today.day:02d}"
    today_title_str = f"ï¼ˆ{date_pattern}ï¼‰"
    
    try:
        resp = requests.get(list_url, headers=headers, timeout=15)
        resp.encoding = 'utf-8'
        soup = BeautifulSoup(resp.text, 'html.parser')
        
        # å¯»æ‰¾åŒ…å« "å¤©ç„¶æ©¡èƒ¶å•†å“æŠ¥ä»·åŠ¨æ€" çš„æ ‡é¢˜
        news_items = soup.find_all('div', class_='list-item') or soup.find_all('li')
        target_url = None
        for item in news_items:
            text = item.get_text()
            if "å¤©ç„¶æ©¡èƒ¶å•†å“æŠ¥ä»·åŠ¨æ€" in text and date_pattern in text:
                link = item.find('a')
                if link and link.get('href'):
                    target_url = link.get('href')
                    if not target_url.startswith('http'):
                        if target_url.startswith('/'):
                            target_url = "https://www.100ppi.com" + target_url
                        else:
                            target_url = "https://www.100ppi.com/" + target_url
                    break
        
        if not target_url:
            print(f"ä»Šæ—¥ ({date_pattern}) å°šæœªå‘å¸ƒå¤©ç„¶æ©¡èƒ¶æŠ¥ä»·åŠ¨æ€ã€‚")
            return None

        print(f"å‘ç°ä»Šæ—¥å¤©ç„¶æ©¡èƒ¶èµ„è®¯: {target_url}ï¼Œæ­£åœ¨è§£æè¯¦æƒ…...")
        detail_resp = requests.get(target_url, headers=headers, timeout=15)
        detail_resp.encoding = 'utf-8'
        detail_soup = BeautifulSoup(detail_resp.text, 'html.parser')
        
        # æŠ“å–è¡¨æ ¼æ•°æ®
        table = detail_soup.find('table')
        if not table:
            print("æœªèƒ½åœ¨è¯¦æƒ…é¡µæ‰¾åˆ°æŠ¥ä»·è¡¨æ ¼ã€‚")
            return None
            
        prices = {}
        rows = table.find_all('tr')
        for row in rows[1:]: # è·³è¿‡è¡¨å¤´
            cols = row.find_all('td')
            if len(cols) >= 4:
                trader = cols[0].get_text(strip=True)
                brand = cols[1].get_text(strip=True)
                price_str = cols[3].get_text(strip=True)
                # æå–æ•°å­—
                import re
                match = re.search(r'(\d+)', price_str)
                if match:
                    key = f"{trader}({brand})"
                    prices[key] = int(match.group(1))
        
        if prices:
            return {
                "date": today.strftime('%Y-%m-%d'),
                "prices": prices,
                "url": target_url
            }
    except Exception as e:
        print(f"æŠ“å–å¤©ç„¶æ©¡èƒ¶æŠ¥ä»·å¤±è´¥: {e}")
    return None

def generate_nr_html(today_nr, history):
    """ä¸ºå¤©ç„¶æ©¡èƒ¶ä»·æ ¼ç”Ÿæˆä¸“å± HTML æŠ¥å‘Š"""
    tz = pytz.timezone('Asia/Shanghai')
    now_str = datetime.now(tz).strftime('%Y-%m-%d %H:%M')
    
    html = f"<h2>ğŸŒ³ å¤©ç„¶æ©¡èƒ¶å•†å“æŠ¥ä»·åŠ¨æ€æŠ¥å‘Š</h2>"
    html += f"<p><b>æ›´æ–°æ—¶é—´:</b> {now_str}</p>"
    
    prices = today_nr['prices']
    avg_price = sum(prices.values()) / len(prices)
    
    html += "<h3>ğŸ“ ä»Šæ—¥äº¤æ˜“å•†æŠ¥ä»·è¯¦æƒ…</h3>"
    html += '<table border="1" style="border-collapse: collapse; width: 100%; text-align: center; font-size: 13px;">'
    html += '<tr style="background:#eee;"><th>äº¤æ˜“å•†(å“ç‰Œ)</th><th>æŠ¥ä»· (å…ƒ/å¨)</th><th>å¯¹æ¯”</th></tr>'
    
    for label, price in prices.items():
        style = ""
        diff_text = "æŒå¹³"
        diff = price - avg_price
        if abs(diff) > 10:
            style = 'style="background-color: #fff9c4;"'
            if diff > 0: 
                diff_text = f'<span style="color:red;">åé«˜ {int(diff)}</span>'
                style = 'style="background-color: #ffcdd2; font-weight:bold;"'
            else: 
                diff_text = f'<span style="color:green;">åä½ {int(abs(diff))}</span>'

        html += f'<tr {style}><td>{label}</td><td>{price}</td><td>{diff_text}</td></tr>'
    html += "</table>"
    
    # æœ€è¿‘è¶‹åŠ¿
    html += "<h3>ğŸ“ˆ æœ€è¿‘ 7 å¤©å‡ä»·èµ°åŠ¿</h3>"
    html += '<table border="1" style="border-collapse: collapse; width: 100%; text-align: center;">'
    html += '<tr style="background:#333; color:white;"><th>æ—¥æœŸ</th><th>å‡ä»·</th><th>å˜åŠ¨</th></tr>'
    
    all_dates = history + [{"date": today_nr['date'], "price": int(avg_price)}]
    recent_7 = all_dates[-7:]
    recent_7.reverse()
    
    for i, entry in enumerate(recent_7):
        price = entry['price']
        change = "æŒå¹³"
        if i < len(recent_7) - 1:
            prev_price = recent_7[i+1]['price']
            diff = price - prev_price
            if diff > 0: change = f'<span style="color:red;">+{int(diff)}</span>'
            elif diff < 0: change = f'<span style="color:green;">-{int(abs(diff))}</span>'
            
        html += f"<tr><td>{entry['date']}</td><td>{price}</td><td>{change}</td></tr>"
    html += "</table>"
    html += f'<p style="font-size:12px;"><a href="{today_nr["url"]}">æŸ¥çœ‹åŸèµ„è®¯é¡µé¢</a></p>'
    
    return html

def load_configs():
    """ä» COMM-CFG ç›®å½•åŠ è½½æ‰€æœ‰ yaml é…ç½®æ–‡ä»¶"""
    configs = []
    if not os.path.exists(CONFIG_DIR):
        print(f"é…ç½®æ–‡ä»¶ç›®å½• {CONFIG_DIR} ä¸å­˜åœ¨")
        return configs

    for file_path in glob.glob(os.path.join(CONFIG_DIR, "*.yaml")):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                if config and 'name' in config and 'url' in config:
                    configs.append(config)
                else:
                    print(f"Skipping invalid config: {file_path}")
        except Exception as e:
            print(f"Error loading {file_path}: {e}")
    return configs

def get_item_hash(item):
    """è®¡ç®—å•æ¡æ•°æ®çš„å”¯ä¸€æŒ‡çº¹"""
    # ç»„åˆå…³é”®å­—æ®µ: æ—¥æœŸ + åç§° + ä»·æ ¼ + å•†å®¶ + è§„æ ¼
    unique_str = f"{item['date_str']}_{item['name']}_{item['price']}_{item['company']}_{item['spec']}"
    return hashlib.md5(unique_str.encode('utf-8')).hexdigest()

def load_processed_records():
    """åŠ è½½å·²å¤„ç†è®°å½•"""
    if not os.path.exists(RECORD_FILE):
        return {"date": "", "hashes": [], "sinopec_done_date": "", "nr_done_date": ""}
    try:
        with open(RECORD_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
            if "sinopec_done_date" not in data: data["sinopec_done_date"] = ""
            if "nr_done_date" not in data: data["nr_done_date"] = ""
            return data
    except Exception:
        return {"date": "", "hashes": [], "sinopec_done_date": "", "nr_done_date": ""}

def save_processed_records(records):
    """ä¿å­˜è®°å½•åˆ°æ–‡ä»¶"""
    if not os.path.exists(DATA_DIR):
        os.makedirs(DATA_DIR)
    
    with open(RECORD_FILE, 'w', encoding='utf-8') as f:
        json.dump(records, f, indent=2, ensure_ascii=False)

def git_commit_changes():
    """å°†çŠ¶æ€æ–‡ä»¶çš„å˜æ›´æäº¤å› Git"""
    try:
        # é…ç½® git ç”¨æˆ· (å¦‚æœæ˜¯ GitHub Actions ç¯å¢ƒ)
        subprocess.run(["git", "config", "--global", "user.name", "github-actions[bot]"], check=True)
        subprocess.run(["git", "config", "--global", "user.email", "github-actions[bot]@users.noreply.github.com"], check=True)
        
        # Add & Commit & Push
        subprocess.run(["git", "add", DATA_DIR], check=True) # æäº¤æ•´ä¸ª data ç›®å½•ï¼ˆåŒ…å«å†å²è®°å½•ï¼‰
        subprocess.run(["git", "commit", "-m", "Auto-update prices and history [skip ci]"], check=False)
        subprocess.run(["git", "push"], check=True)
        print("å·²æˆåŠŸæäº¤çŠ¶æ€è®°å½•æ›´æ–°ã€‚")
    except Exception as e:
        print(f"Git æäº¤å¤±è´¥ (æœ¬åœ°è¿è¡Œå¯å¿½ç•¥): {e}")

def get_price_data(config):
    """æ ¹æ®é…ç½®çˆ¬å–æ•°æ®ï¼Œå¹¶è¿›è¡Œå…³é”®è¯è¿‡æ»¤"""
    name = config.get('name')
    url = config.get('url')
    invalid_keywords = config.get('invalid_keywords', []) or []
    
    print(f"æ­£åœ¨è·å– {name} çš„æŠ¥ä»·ä¿¡æ¯...")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    all_prices = []
    
    try:
        response = requests.get(url, headers=headers, timeout=15)
        response.encoding = 'utf-8'
        
        if response.status_code != 200:
            print(f"[{name}] è¯·æ±‚å¤±è´¥: {response.status_code}")
            return []

        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ä¼˜åŒ–: å°è¯•å¤šä¸ªå¯èƒ½çš„è¡¨æ ¼é€‰æ‹©å™¨ï¼Œç¡®ä¿æŠ“åˆ°çš„æ˜¯æ•°æ®è¡¨è€Œä¸æ˜¯å¯¼èˆªè¡¨
        target_table = None
        
        # ä¼˜å…ˆçº§1: å¸¦æœ‰ç‰¹å®šç±»çš„è¡¨æ ¼
        for cls in ['list-tbl', 'lp-table']:
            t = soup.find('table', class_=cls)
            if t:
                target_table = t
                break
        
        # ä¼˜å…ˆçº§2: éå†æ‰€æœ‰è¡¨æ ¼ï¼Œå¯»æ‰¾åŒ…å«å…³é”®è¯çš„è¡¨æ ¼
        if not target_table:
            tables = soup.find_all('table')
            for t in tables:
                if "å•†å“åç§°" in t.get_text() or "æŠ¥ä»·" in t.get_text():
                    target_table = t
                    break

        if not target_table:
            print(f"[{name}] æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®è¡¨æ ¼ã€‚")
            return []

        rows = target_table.find_all('tr')
        
        # è§£ææ•°æ®
        valid_row_count = 0
        for i, row in enumerate(rows):
            cols = row.find_all('td')
            # å¿…é¡»æ»¡è¶³è‡³å°‘ 8 åˆ— (å•†å“, è§„æ ¼, å‚å®¶, ä»·æ ¼, ç±»å‹, åœ°åŒº, äº¤æ˜“å•†, æ—¥æœŸ)
            if len(cols) < 8:
                continue
            
            valid_row_count += 1
            
            # è§£æåŸå§‹æ–‡æœ¬
            product_name = cols[0].get_text(strip=True)
            spec = cols[1].get_text(strip=True)
            price = cols[3].get_text(strip=True)
            company = cols[6].get_text(strip=True)
            date_str = cols[7].get_text(strip=True)
            
            # 1. å…³é”®è¯è¿‡æ»¤
            full_text = f"{product_name} {spec} {price} {company}"
            is_invalid = False
            for kw in invalid_keywords:
                if kw in full_text:
                    is_invalid = True
                    break
            
            if is_invalid:
                continue
                
            # 2. æ ¼å¼åŒ–æ•°æ®å¹¶å­˜å…¥
            try:
                row_date = datetime.strptime(date_str, '%Y-%m-%d').date()
                all_prices.append({
                    "name": name, 
                    "raw_name": product_name,
                    "spec": spec,
                    "price": price,
                    "company": company,
                    "date": row_date,
                    "date_str": date_str
                })
            except ValueError:
                continue
        
        print(f"[{name}] æ‰«æå®Œæ¯•ã€‚è¿‡æ»¤åæœ‰æ•ˆ: {len(all_prices)}")

    except Exception as e:
        print(f"[{name}] çˆ¬å–å¼‚å¸¸: {e}")

    return all_prices

def organize_data(all_prices, sent_hashes):
    """æ•´ç†æ•°æ®"""
    tz = pytz.timezone('Asia/Shanghai')
    today = datetime.now(tz).date()
    yesterday = today - timedelta(days=1)
    
    today_data = []
    yesterday_data = []
    new_items_count = 0
    
    for item in all_prices:
        item_hash = get_item_hash(item)
        item['is_new'] = False
        
        if item['date'] == today:
            if item_hash not in sent_hashes:
                item['is_new'] = True
                new_items_count += 1
            today_data.append(item)
        elif item['date'] == yesterday:
            yesterday_data.append(item)
    
    yesterday_slice = yesterday_data[:3]
    return today_data, yesterday_slice, new_items_count

def generate_html_report(today_data, yesterday_data):
    """ç”Ÿæˆç»Ÿä¸€çš„ HTML æŠ¥è¡¨å†…å®¹"""
    tz = pytz.timezone('Asia/Shanghai')
    now_str = datetime.now(tz).strftime('%Y-%m-%d %H:%M')
    
    html = f"<h3>ğŸ“… å¸‚åœºæ•£æˆ·æŠ¥ä»·æ›´æ–° ({now_str})</h3>"
    html += """
    <table border="1" style="border-collapse: collapse; width: 100%; font-size: 14px;">
        <tr style="background-color: #333; color: white;">
            <th>æ—¥æœŸ</th>
            <th>åç§°</th>
            <th>ä»·æ ¼</th>
            <th>å•†å®¶</th>
        </tr>
    """
    for item in today_data:
        row_style = "background-color: #ffcdd2; font-weight: bold; border: 2px solid red;" if item.get('is_new') else "background-color: #fff9c4;"
        date_display = f"{item['date_str']} (NEW)" if item.get('is_new') else item['date_str']
        html += f'<tr style="{row_style}"><td style="color: #d32f2f;">{date_display}</td><td>{item["raw_name"]}<br><span style="font-size:12px;color:gray;">{item["spec"]}</span></td><td style="color: red; font-size: 16px;">{item["price"]}</td><td>{item["company"]}</td></tr>'
        
    for item in yesterday_data:
        html += f'<tr style="background-color: #f5f5f5; color: #666;"><td>{item["date_str"]}</td><td>{item["raw_name"]}<br><span style="font-size:12px;color:gray;">{item["spec"]}</span></td><td>{item["price"]}</td><td>{item["company"]}</td></tr>'
        
    html += "</table><p style='font-size:12px; color: gray;'>æ³¨: çº¢è‰²ä¸ºæœ€æ–°ï¼Œé»„è‰²ä¸ºä»Šæ—¥æ—§é—»ï¼Œç°è‰²ä¸ºæ˜¨æ—¥å‚è€ƒã€‚</p>"
    return html

def send_notification(html_content):
    """é€šè¿‡ PushPlus å‘é€å¾®ä¿¡é€šçŸ¥"""
    if not PUSHPLUS_TOKEN: return False
    tz = pytz.timezone('Asia/Shanghai')
    title = f"ğŸ“¢ ä¸äºŒçƒ¯ä»·æ ¼æ›´æ–° ({datetime.now(tz).strftime('%H:%M')})"
    try:
        resp = requests.post("http://www.pushplus.plus/send", json={"token": PUSHPLUS_TOKEN, "title": title, "content": html_content, "template": "html"}, timeout=20)
        return resp.status_code == 200
    except: return False

def send_email_notification(html_content):
    """é€šè¿‡ SMTP å‘é€ QQ é‚®ä»¶é€šçŸ¥"""
    if not all([EMAIL_SENDER, EMAIL_AUTH_CODE, EMAIL_RECEIVER]): return False
    tz = pytz.timezone('Asia/Shanghai')
    msg = MIMEText(html_content, 'html', 'utf-8')
    msg['Subject'] = Header(f"ä¸äºŒçƒ¯æŠ¥ä»·æ›´æ–°æœåŠ¡ - {datetime.now(tz).strftime('%Y-%m-%d %H:%M')}", 'utf-8')
    msg['From'] = EMAIL_SENDER
    msg['To'] = EMAIL_RECEIVER
    try:
        server = smtplib.SMTP_SSL("smtp.qq.com", 465, timeout=15)
        server.login(EMAIL_SENDER, EMAIL_AUTH_CODE)
        server.sendmail(EMAIL_SENDER, [EMAIL_RECEIVER], msg.as_string())
        try: server.quit()
        except: pass
        return True
    except Exception as e:
        if "(-1," in str(e): return True
        return False

def main():
    tz = pytz.timezone('Asia/Shanghai')
    now = datetime.now(tz)
    today_str = now.strftime('%Y-%m-%d')
    print(f"[{now.strftime('%Y-%m-%d %H:%M:%S')}] è„šæœ¬å¯åŠ¨...")
    
    records = load_processed_records()
    if records["date"] != today_str:
        records.update({
            "date": today_str, 
            "hashes": [], 
            "sinopec_done_date": records.get("sinopec_done_date", ""),
            "nr_done_date": records.get("nr_done_date", "")
        })
    
    # --- ä»»åŠ¡ 1: ä¸­çŸ³åŒ–ä¸äºŒçƒ¯ä¸“åœº ---
    sinopec_triggered = False
    if records.get("sinopec_done_date") != today_str:
        if 9 <= now.hour <= 17: # æ‰©å¤§æµ‹è¯•çª—å£
            print("æ­£åœ¨ç›‘æµ‹ä¸­çŸ³åŒ–ä¸äºŒçƒ¯æŠ¥ä»·...")
            sinopec_data = get_sinopec_factory_price()
            if sinopec_data:
                history = []
                if os.path.exists(SINOPEC_HISTORY_FILE):
                    with open(SINOPEC_HISTORY_FILE, 'r', encoding='utf-8') as f:
                        history = json.load(f)
                html = generate_sinopec_html(sinopec_data, history)
                if send_notification(html) or send_email_notification(html):
                    avg_p = sum(sinopec_data['prices'].values()) / len(sinopec_data['prices'])
                    history.append({"date": today_str, "price": int(avg_p), "is_sinopec": True})
                    with open(SINOPEC_HISTORY_FILE, 'w', encoding='utf-8') as f:
                        json.dump(history, f, indent=2, ensure_ascii=False)
                    records["sinopec_done_date"] = today_str
                    sinopec_triggered = True
                    save_processed_records(records)
                    git_commit_changes()

    # --- ä»»åŠ¡ 2: å¤©ç„¶æ©¡èƒ¶ä¸“åœº ---
    nr_triggered = False
    if records.get("nr_done_date") != today_str:
        if 9 <= now.hour <= 17: # ä¸ä¸­çŸ³åŒ–çª—å£ä¸€è‡´
            print("æ­£åœ¨ç›‘æµ‹å¤©ç„¶æ©¡èƒ¶å½“æ—¥åŠ¨æ€...")
            nr_data = get_natural_rubber_price()
            if nr_data:
                history = []
                if os.path.exists(NR_HISTORY_FILE):
                    with open(NR_HISTORY_FILE, 'r', encoding='utf-8') as f:
                        history = json.load(f)
                html = generate_nr_html(nr_data, history)
                # ä½¿ç”¨ä¸“é—¨çš„æ ‡é¢˜æ¨é€
                if send_notification(html) or send_email_notification(html):
                    print("ä»Šæ—¥å¤©ç„¶æ©¡èƒ¶æŠ¥ä»·å·²æˆåŠŸæ¨é€å¹¶å½’æ¡£ã€‚")
                    avg_p = sum(nr_data['prices'].values()) / len(nr_data['prices'])
                    history.append({"date": today_str, "price": int(avg_p), "note": "Average"})
                    with open(NR_HISTORY_FILE, 'w', encoding='utf-8') as f:
                        json.dump(history, f, indent=2, ensure_ascii=False)
                    records["nr_done_date"] = today_str
                    nr_triggered = True
                    save_processed_records(records)
                    git_commit_changes()

    # --- ä»»åŠ¡ 3: å¸‚åœºæ•£æˆ·è½®è¯¢ ---
    # å¦‚æœä¸­çŸ³åŒ–è¿˜æ²¡å‡ºï¼Œæ‰§è¡Œæ•£æˆ·è½®è¯¢
    if records.get("sinopec_done_date") != today_str:
        print("æ‰§è¡Œå¸¸è§„æ•£æˆ·ä¸äºŒçƒ¯æŠ¥ä»·è½®è¯¢...")
        configs = load_configs()
        sent_hashes = set(records["hashes"])
        all_items = []
        for cfg in configs: all_items.extend(get_price_data(cfg))
        
        today_data, yesterday_data, new_count = organize_data(all_items, sent_hashes)
        if new_count > 0:
            html = generate_html_report(today_data, yesterday_data)
            if send_notification(html) or send_email_notification(html):
                for item in today_data:
                    if item.get('is_new'): records["hashes"].append(get_item_hash(item))
                save_processed_records(records)
                git_commit_changes()
    else:
        if not sinopec_triggered:
            print("ä»Šæ—¥ä¸­çŸ³åŒ–æŠ¥ä»·å·²å®Œæˆï¼Œæ•£æˆ·å¸¸è§„è½®è¯¢å·²è·³è¿‡ã€‚")

if __name__ == "__main__":
    main()
